\documentclass[a4paper,10pt]{book}

%Use the following for font size 8 or 9, as 10 is the minimum provided normally
%\documentclass[8pt]{extbook}

%Compilers
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}

%Graphics
\usepackage{xcolor}
\usepackage{graphicx}

%Math
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{caption}
\usepackage{braket}
\usepackage{amsthm}
\usepackage{mathtools}
\usepackage[xcolor]{mdframed}

%Math shortcuts 
\newcommand{\R}{\mathbb{R}}
\newcommand{\C}{\mathbb{C}}
\newcommand{\F}{\mathbb{F}}
\newcommand{\M}{\mathcal{M}}
\renewcommand{\P}{\mathcal{P}}
\renewcommand{\L}{\mathcal{L}}
\DeclareMathOperator{\Span}{span}

%Augmented matrices
\makeatletter
\renewcommand*\env@matrix[1][*\c@MaxMatrixCols c]{%
   \hskip -\arraycolsep
   \let\@ifnextchar\new@ifnextchar
   \array{#1}}
\makeatother


%Define abs
\DeclarePairedDelimiter\abs{\lvert}{\rvert}

%Defining norm
\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}

%Defining inner product
\DeclarePairedDelimiterX{\inp}[2]{\langle}{\rangle}{#1, #2}


%Reducing margin
\usepackage[margin=2cm]{geometry}

%Header, footer
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\rhead{\leftmark}
\cfoot{\thepage} 
\renewcommand{\headrulewidth}{0pt}

%Index - not used
\usepackage{makeidx}
\makeindex


%Theorem instantiation
\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[section]
\definecolor{lightblue1}{RGB}{222, 243, 253}
\surroundwithmdframed[
	hidealllines = true, 
	backgroundcolor = lightblue1,
	]{theorem}
	
%Proof instantiation 
\definecolor{lightblue2}{RGB}{232, 245, 252}
\surroundwithmdframed[
	hidealllines = true, 
	backgroundcolor = lightblue2,
	]{proof}
	
%Lemma instantiation
\theoremstyle{plain}
\newtheorem{lemma}[theorem]{Lemma}
\definecolor{lightgreen1}{RGB}{224, 255, 193}

\surroundwithmdframed[
	hidealllines = true, 
	backgroundcolor = lightgreen2,
	]{lemma}

%Lemma Proof instantiation 
\theoremstyle{remark}
\newtheorem*{lproof}{Proof}
\definecolor{lightgreen2}{RGB}{232, 249, 214}

\surroundwithmdframed[
	hidealllines = true, 
	backgroundcolor = lightgreen2,
	]{lproof}

%Definition instantiation
\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]
\definecolor{lightgreen}{RGB}{219, 255, 188}
\definecolor{subtlegray}{RGB}{248, 248, 248}
\surroundwithmdframed[
	hidealllines = true, 
	backgroundcolor = subtlegray,
	]{definition}
	
%Change QED symbol to solid black square
\renewcommand\qedsymbol{$\blacksquare$}

	
	
%Remove auto-indentation
\setlength{\parindent}{0cm}

%Preferred font and spacing
\linespread{1.3}
%\usepackage{lmodern}
\usepackage{kpfonts}
%\usepackage{tgschola}


\begin{document}

\frontmatter 
{\let\cleardoublepage\clearpage 
%Fancy shmancy title page - code from https://en.wikibooks.org/wiki/LaTeX/Title_Creation
\begin{titlepage}
	\centering
	{\scshape\LARGE University of California, Berkeley \par}
	\vspace{3cm}
	{\scshape\Large Literally everything I know about \par}
	\vspace{1.5cm}
	{\huge\bfseries Linear Algebra\par}
	\vspace{2.5cm}
	{\Large\itshape Warren Alphonso\par}
	\vfill
	{\large A very reductionist summary of \textsc{Linear Algebra and its Applications} by Lay, Lay, and McDonald, as well as \textsc{Linear Algebra Done Wrong} by Treil. \par}
	\vfill
	{\large \today\par}
\end{titlepage}

\tableofcontents
}

\mainmatter

\chapter{Bilinear and Quadratic Forms}

\section{Main Definitions}

\begin{definition}
A \textbf{bilinear form on $\R^{n}$} is a function $L(x, y)$ of arguments $x, y \in \R^{n}$ which is linear in each argument. That is 
\begin{enumerate}
	\item $L(\alpha x_{1} + \beta x_{2}, y) = \alpha L(x_{1}, y) + \beta L(x_{2}, y)$
	\item $L(x, \alpha y_{1} + \beta y_{2}) = \alpha L(x, y_{1}) + \beta L(x, y_{2})$
\end{enumerate}

If $x = \begin{bmatrix}
x_{1} \\
\vdots \\
x_{n}
\end{bmatrix}$ and $y = \begin{bmatrix}
y_{1} \\
\vdots \\
y_{n}
\end{bmatrix}$, a bilinear form can be written as 
$$L(x, y) = \sum_{j, k = 1}^{n} a_{jk} x_{k} y_{j}$$
or in matrix form 
$$L(x, y) = (Ax, y)$$
where the matrix $A$ is uniquely determined by the bilinear form $L$.
\end{definition}

\begin{definition}
There are many definitions of a quadratic form. 

One can define a quadratic form on $\R^{n}$ as the ``diagonal" of a bilinear form $L$, that is, any quadratic form $Q$ is defined as $Q[x] = L(x, x) = (Ax, x)$. 

Another definition is to say a quadratic form is a homogeneous second degree polynomial, that is, $Q$ is a polynomial of $n$ variables $x_{1}, \cdots, x_{n}$ having only terms of degree 2 (only terms $ax_{k}^{2}$ and $cx_{j} x_{k}$ are allowed).

There are infinitely many ways to write a quadratic form as $Q[x] = (Ax, x)$, but if we require $A$ to be \textit{symmetric} ($A^{T} = A$), then $A$ will be unique. 

Any \textbf{quadratic form $Q[x]$ on $\R^{n}$} admits a unique representation $Q[x] = (Ax, x)$ where $A$ is a real symmetric matrix. 

We can extend this definition to $\C^{n}$ by taking the self-adjoint transformation, $A = A^{*}$ and defining $Q[x] = (Ax, x)$. Unless explicitly noted, all our theorems will be true in the complex case as well. 

\end{definition}

The only essential difference is that in the complex case we have no choice: a real quadratic form corresponds to a Hermitian matrix. 

\begin{theorem}
$(Ax, x)$ is real for all $x \in \C^{n}$ if and only if $A = A^{*}$.  
\end{theorem}

\begin{proof}
To prove if: 
$$(Ax, x) = (x, A^{*} x) = (x, Ax) = \overline{(Ax, x)}$$

To prove only if: Consider the expression $(A (x + zy), x + zy)$. We assume it is real for all $z \in \C$. Now we can write 
$$
\begin{aligned}
\Big( A (x + zy), x + zy \Big) &= ( Ax + Azy, x + zy) \\
&= \overline{(x, Ax)} + \overline{(zy, Ax)} + \overline{(x, Azy)} + \overline{(zy, Azy)} \\ 
&= (Ax, x) + \overline{z} (Ax, y) + z (Ay, x) + z \overline{z} (Ay, y)
\end{aligned}
$$

We know that the final sum must be real. Since only the middle two terms can contribute to an imaginary solution, we know 
$$\overline{z} (Ax, y) + z (Ay, x) \in \R$$
Because $z$ can be any complex number, we know $z \neq \overline{z}$, so for the imaginary parts to cancel, we must have
$$(Ax, y) = (Ay, x)$$
and because we know $(Ax, y) = (x, A^{*} y)$, this means that $A^{*} = A$. 
\end{proof}

\section{Diagonalization of Quadratic Forms}

Quadratic forms are common; they appear in the study of curves in $\R^{2}$ and some surfaces in $\R^{3}$, for example. If we are given a set in $\R^{n}$ defined by $Q[x] = 1$, where $Q$ is some quadratic form, we want to understand the structure of this set. We will try our usual approach of doing so using a change of variables. 

\subsection{Orthogonal Diagonalization}

Suppose we have a quadratic form $Q[x] = (Ax, x)$ in $\F^{n}$. We define $y = S^{-1} x$, where $S$ is any invertible $n \times n$ matrix. Now, we have
$$Q[x] = Q[Sy] = (ASy, Sy) = (S^{*} AS y, y)$$
so when written in variable $y$, the quadratic form has matrix $S^{*}AS$. 

Now our goal is to find an invertible matrix $S$ such that $S^{*} AS$ is diagonal. Using diagonalization, we can write $A = UDU^{*}$ because $A$ is symmetric, which means it's unitary and for unitary matrices $U^{*} = U^{-1}$. Then, we have $D = U^{*} AU$, so in $y = U^{-1} x$, the quadratic form has diagonal matrix. 

Geometrically, the columns of $U$ form an orthonormal basis in $\F^{n}$, which we'll call $B$. The change of coordinate matrix $[I]_{S, B}$ from $B$ to the standard basis is exactly $U$. Since $y = U^{-1} x$, the coordinates $y_{1}, \cdots, y_{n}$ can be interpreted as coordinates of the vector $x$ in the new basis $B$. So, orthogonal diagonalization allows us to visualize the set $Q[x] = 1$ very well if we can visualize it for diagonal matrices. 

\textbf{Example:} Consider $Q[x, y] = 2x^{2} + 2y^{2} + 2xy$. We want to describe the set of points $(x, y) \in \R^{2} : Q(x, y) = 1$. 

The matrix $A$ of $Q$ is 
$$A = \begin{bmatrix}
2 & 1 \\
1 & 2
\end{bmatrix}$$ 
After orthogonally diagonalizing $A$, we can write 
$$A = U \begin{bmatrix}
3 & 0 \\
0 & 3
\end{bmatrix} U^{*} \qquad \text{ where } U = \frac{1}{\sqrt{2}} \begin{bmatrix}
1 & -1 \\
1 & 1
\end{bmatrix}$$
which means
$$U^{*} AU = \begin{bmatrix}
3 & 0 \\
0 & 1
\end{bmatrix} = D$$

This tells us the set $\{y : (Dy, y) = 1\}$ is the ellipse with half-axes $\frac{1}{\sqrt{3}}$ and 1. Thus, the set $\{x \in \R^{2}: (Ax, x) = 1 \}$ is the same ellipse but in the basis $\begin{bmatrix}
\frac{1}{\sqrt{2}} \\
\frac{1}{\sqrt{2}}
\end{bmatrix}, \begin{bmatrix}
-\frac{1}{\sqrt{2}} \\
\frac{1}{\sqrt{2}}
\end{bmatrix}$, or in other words, the same ellipse rotated $\frac{\pi}{4}$. 

\subsection{Non-orthogonal Diagonalization} 

















\end{document}